{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKPpMImnmX7mCzL33QtB8r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mugalan/item-response-prediction/blob/main/item_response_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview"
      ],
      "metadata": {
        "id": "r9K-WKVTC6uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A high-level, production-friendly wrapper for adaptive item recommendation and Bayesian ability estimation over (\\theta \\in [0,1]), built on top of:\n",
        "\n",
        "* `Bayesian2PL` — grid-based Bayesian estimator for 2PL and ideal-point likelihoods\n",
        "* `ItemizedBayesian2PL` — convenience helpers for item dict pools\n",
        "* `ItemResponsePredictionRunner` — orchestration (posterior, bandit head, plots)\n",
        "\n",
        "`ItemResponsePrediction` exposes a clean, minimal API for:\n",
        "\n",
        "* **Recommending the next item** to present based on your chosen engine/policy\n",
        "* **Updating the posterior** and bandit statistics from an observed response\n",
        "* **Resetting/replacing the item pool** (with optional plots)\n",
        "\n",
        "---\n",
        "\n",
        "## Features\n",
        "\n",
        "* **Two likelihoods**\n",
        "\n",
        "  * 2PL logistic (parameters (a>0), (b \\in [0,1]))\n",
        "  * Ideal-point logistic (parameters (\\kappa>0), (\\gamma), (b \\in [0,1]))\n",
        "* **Engines**: `bayes`, `bandit`, `hybrid`\n",
        "* **Policies** (Bayes): `thompson`, `greedy`, `ucb`, `bayesucb`, `max_info`, `closest_b`\n",
        "* **Bandit strategies** (via runner): discounted UCB and Beta variants\n",
        "* **Posterior-predictive scoring** of items\n",
        "* **Exposure caps** (temporarily mask over-exposed items)\n",
        "* **Plotly visualizations** for posterior and per-item curves\n",
        "* **Audit-friendly metadata** returned with each call\n",
        "\n",
        "---\n",
        "\n",
        "## Installation & Requirements\n",
        "\n",
        "This module is pure Python. Dependencies used by the supporting classes/examples:\n",
        "\n",
        "```bash\n",
        "python >= 3.9\n",
        "numpy\n",
        "plotly\n",
        "```\n",
        "\n",
        "If you plan to run the plotting utilities, ensure Plotly is installed:\n",
        "\n",
        "```bash\n",
        "pip install numpy plotly\n",
        "```\n",
        "\n",
        "> **Note**: The wrapper depends on the presence of `Bayesian2PL`, `ItemizedBayesian2PL`, and `ItemResponsePredictionRunner` in your module path. Make sure these classes are imported/defined before using `ItemResponsePrediction`.\n",
        "\n",
        "---\n",
        "\n",
        "## Concepts at a Glance\n",
        "\n",
        "* **Ability ((\\theta))**: Learner/user latent skill; supported on `[0,1]` with a Beta prior.\n",
        "* **Item parameters**\n",
        "\n",
        "  * 2PL: difficulty `b ∈ [0,1]`, discrimination `a > 0`.\n",
        "  * Ideal-point: location `b ∈ [0,1]`, sharpness `κ > 0`, height/offset `γ`.\n",
        "* **Posterior**: Grid approximation (default 1001 points) with numerically safe log-space normalization.\n",
        "* **Recommendation**: Combines Bayesian CAT-style scoring and/or bandit exploration; hybrid mixes both.\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "```python\n",
        "from your_module import ItemResponsePrediction\n",
        "\n",
        "items = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.30, \"kappa\": 40.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q2\", \"b\": 0.45, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.60, \"kappa\": 60.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(\n",
        "    likelihood=\"ideal\",      # or \"2pl\"\n",
        "    engine=\"hybrid\",         # \"bayes\" | \"bandit\" | \"hybrid\"\n",
        "    policy=\"ucb\",            # used by bayes engine\n",
        "    hybrid_eta=0.5,\n",
        "    items=items,\n",
        ")\n",
        "\n",
        "# 1) Ask for a recommendation (does NOT modify state)\n",
        "rec = irp.recommend()\n",
        "print(rec[\"response\"][\"meta_data\"][\"item\"])  # the recommended item dict\n",
        "\n",
        "# 2) Record an observed outcome for that label (updates posterior & bandit)\n",
        "label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "step_out = irp.update_estimator(label=label, outcome=1)  # 1=correct/positive, 0=incorrect/negative\n",
        "\n",
        "# 3) Repeat recommend → update loop\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Data Schemas\n",
        "\n",
        "### Item dictionaries (recommended)\n",
        "\n",
        "* **2PL**: `{\"label\": str, \"b\": float in [0,1], \"a\": float > 0}`\n",
        "* **Ideal-point**: `{\"label\": str, \"b\": float in [0,1], \"kappa\": float > 0, \"gamma\": float}`\n",
        "\n",
        "### Legacy arrays (also supported by the runner)\n",
        "\n",
        "* Provide `B` (and `A` or `K`/`Gm` depending on the likelihood). `ItemResponsePrediction` prefers item dicts.\n",
        "\n",
        "---\n",
        "\n",
        "## API Reference: `ItemResponsePrediction`\n",
        "\n",
        "### Constructor\n",
        "\n",
        "```python\n",
        "ItemResponsePrediction(\n",
        "    *,\n",
        "    grid_points: int = 1001,\n",
        "    alpha: float = 1.0,\n",
        "    beta: float = 1.0,\n",
        "    default_a: float = 4.0,\n",
        "    likelihood: str = \"ideal\",\n",
        "    engine: str = \"hybrid\",\n",
        "    policy: str = \"ucb\",\n",
        "    bandit_discount: float = 0.97,\n",
        "    bandit_c: float = 0.50,\n",
        "    bandit_alpha0: float = 1.0,\n",
        "    bandit_beta0: float = 1.0,\n",
        "    hybrid_eta: float = 0.5,\n",
        "    max_exposures_per_item: int = 0,\n",
        "    items: Optional[Sequence[dict]] = None,\n",
        "    B: Optional[Sequence[float]] = None,\n",
        "    A: Optional[Sequence[float]] = None,\n",
        "    K: Optional[Sequence[float]] = None,\n",
        "    Gm: Optional[Sequence[float]] = None,\n",
        "    estimator: Optional[Any] = None,\n",
        ")\n",
        "```\n",
        "\n",
        "* **`likelihood`**: `\"2pl\"` or `\"ideal\"`.\n",
        "* **`engine`**: `\"bayes\"`, `\"bandit\"`, or `\"hybrid\"`.\n",
        "* **`policy`** (Bayes engine): `\"thompson\" | \"greedy\" | \"ucb\" | \"bayesucb\" | \"max_info\" | \"closest_b\"`.\n",
        "* **`max_exposures_per_item`**: `0` means unlimited; `>0` temporarily masks over-exposed items.\n",
        "\n",
        "### `recommend()` → dict\n",
        "\n",
        "Returns an envelope with `status`, `message`, and `response`:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"status\": \"success\",\n",
        "  \"response\": {\n",
        "    \"meta_data\": {\n",
        "      \"step\": int,\n",
        "      \"idx\": int,\n",
        "      \"item\": { ... },\n",
        "      \"p_pred_before\": float,\n",
        "      \"exposures\": int,\n",
        "      \"avg_reward\": float,\n",
        "      \"reward_sum\": float,\n",
        "      \"trials\": int,\n",
        "      \"picker_engine\": \"bayes\" | \"bandit\" | \"hybrid\",\n",
        "      \"bayes_index\": Optional[int],\n",
        "      \"bandit_index\": Optional[int],\n",
        "      ...\n",
        "    },\n",
        "    \"data\": {\"figure\": \"\"},\n",
        "    \"message\": str\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "> Side-effect free: does not update posterior or bandit stats.\n",
        "\n",
        "### `update_estimator(label: str, outcome: int, show_plots: bool=False)` → dict\n",
        "\n",
        "* Updates the posterior with the observed binary outcome for the given item `label`.\n",
        "* Records the outcome into the bandit head (discounted counts or Beta posterior depending on strategy).\n",
        "* Returns an envelope including a Plotly HTML string of the updated (\\theta) posterior.\n",
        "\n",
        "### `reset_estimator(alpha=None, beta=None, clear_bandit=True, clear_exposures=True, items=None, likelihood=None)` → dict\n",
        "\n",
        "* **Soft reset**: when only `alpha/beta` change (and no new items), the grid estimator is reset to the prior.\n",
        "* **Full rebuild**: when `items` are provided; installs new pool, clears bandit state and exposures.\n",
        "* Returns an envelope with metadata and (if items provided) a Plotly HTML figure showing per-item probability profiles.\n",
        "\n",
        "---\n",
        "\n",
        "## Engines & Policies (Behavioral Summary)\n",
        "\n",
        "### Bayes engine\n",
        "\n",
        "Scores each candidate by posterior-expected success (or related info):\n",
        "\n",
        "* `greedy`: maximize expected success\n",
        "* `ucb`: expected success + κ × posterior std\n",
        "* `thompson`: sample (\\theta) from the posterior; pick best given that draw\n",
        "* `bayesucb`: quantile-based optimistic selection w.r.t. (\\theta) or (p)\n",
        "* `max_info`: maximize Fisher information under the posterior mixture\n",
        "* `closest_b`: heuristic — pick item with `b` closest to current (E[\\theta])\n",
        "\n",
        "### Bandit engine\n",
        "\n",
        "Tracks *arm-level* discounted rewards and chooses with:\n",
        "\n",
        "* Discounted UCB\n",
        "* Beta-TS / Beta-UCB / Beta-mean variants (effective α/β updated with discounting)\n",
        "\n",
        "### Hybrid engine\n",
        "\n",
        "Convex combination of normalized Bayes and Bandit scores: `mix = (1-η)*Bayes + η*Bandit`.\n",
        "\n",
        "---\n",
        "\n",
        "## Likelihood Details\n",
        "\n",
        "### 2PL Logistic\n",
        "\n",
        "[ p(y=1 \\mid \\theta, a, b) = \\sigma\\big(a(\\theta - b)\\big) ]\n",
        "\n",
        "* `a > 0` (discrimination); `b ∈ [0,1]` (difficulty)\n",
        "\n",
        "### Ideal-Point Logistic\n",
        "\n",
        "[ p(y=1 \\mid \\theta, \\kappa, \\gamma, b) = \\sigma\\big(\\gamma - \\kappa (\\theta - b)^2\\big) ]\n",
        "\n",
        "* `κ > 0` (sharpness); `γ` (height/offset); `b ∈ [0,1]`\n",
        "\n",
        "Both are numerically stabilized by clipping logits and probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "## End-to-End Examples\n",
        "\n",
        "### A. Ideal-point, item dict pool\n",
        "\n",
        "```python\n",
        "items = [\n",
        "    {\"label\": \"I1\", \"b\": 0.25, \"kappa\": 35.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I2\", \"b\": 0.50, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I3\", \"b\": 0.75, \"kappa\": 70.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(likelihood=\"ideal\", engine=\"hybrid\", policy=\"ucb\", items=items)\n",
        "\n",
        "for t in range(5):\n",
        "    rec = irp.recommend()\n",
        "    label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "\n",
        "    # fake outcome: higher success near b≈0.5\n",
        "    import random\n",
        "    y = 1 if random.random() < (0.8 if label==\"I2\" else 0.5) else 0\n",
        "\n",
        "    out = irp.update_estimator(label, y)\n",
        "    print(out[\"response\"][\"meta_data\"][\"theta_hat\"], out[\"response\"][\"meta_data\"][\"avg_reward\"])\n",
        "```\n",
        "\n",
        "### B. 2PL, item dict pool with discrimination\n",
        "\n",
        "```python\n",
        "items_2pl = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.35, \"a\": 3.5},\n",
        "    {\"label\": \"Q2\", \"b\": 0.50, \"a\": 4.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.70, \"a\": 5.0},\n",
        "]\n",
        "\n",
        "irp2 = ItemResponsePrediction(likelihood=\"2pl\", engine=\"bayes\", policy=\"thompson\", items=items_2pl)\n",
        "rec = irp2.recommend()\n",
        "print(\"Recommend:\", rec[\"response\"][\"meta_data\"][\"item\"])  # inspect choice\n",
        "\n",
        "# Suppose user answered Q2 incorrectly (0)\n",
        "out = irp2.update_estimator(\"Q2\", 0)\n",
        "print(\"theta(mean):\", out[\"response\"][\"meta_data\"][\"theta_hat\"])\n",
        "```\n",
        "\n",
        "### C. Reset with a new pool and prior\n",
        "\n",
        "```python\n",
        "new_items = [\n",
        "    {\"label\": \"N1\", \"b\": 0.40, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"N2\", \"b\": 0.60, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "r = irp.reset_estimator(alpha=2.0, beta=2.0, items=new_items, likelihood=\"ideal\")\n",
        "print(r[\"status\"], r[\"response\"][\"meta_data\"][\"posterior_summary\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Tips & Best Practices\n",
        "\n",
        "* Use **item dictionaries** with explicit labels — simpler and safer than managing parallel arrays.\n",
        "* For early-stage users, prefer **wider priors** (e.g., `alpha=1, beta=1`) and a **hybrid** engine for balanced exploration.\n",
        "* If you want faster convergence when the pool is calibrated, try **Bayes `max_info`** or **`ucb`**.\n",
        "* Apply a **reasonable exposure cap** in large pools (e.g., `max_exposures_per_item=2`) to avoid overusing the same item.\n",
        "* Inspect the returned Plotly HTML to sanity-check the posterior evolution during development.\n",
        "\n",
        "---\n",
        "\n",
        "## Numerical Notes\n",
        "\n",
        "* Logits and probabilities are clipped to avoid under/overflow.\n",
        "* Posterior normalization uses the trapezoidal rule; set `grid_points ≥ 101` (default 1001).\n",
        "* The Beta prior is parameterized as `Beta(alpha, beta)` on `[0,1]`.\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "* **ValueError: item keys missing** — ensure your items match the likelihood schema.\n",
        "* **All candidates masked** — if using `max_exposures_per_item`, the runner will temporarily unmask all if everything is at cap.\n",
        "* **Posterior looks flat** — try increasing `grid_points`, narrowing the prior, or presenting more discriminating items.\n",
        "* **No Plotly output** — install `plotly` and ensure your environment can render/save HTML snippets.\n",
        "\n",
        "---\n",
        "\n",
        "## FAQ\n",
        "\n",
        "**Q: Does `recommend()` update the posterior?**\n",
        "A: No. It is side-effect free. Call `update_estimator(label, outcome)` after the user responds.\n",
        "\n",
        "**Q: Can I plug in my own estimator?**\n",
        "A: Yes. You can pass a pre-built `Bayesian2PL`-compatible estimator to the runner (advanced use). The `ItemResponsePrediction` wrapper focuses on the common case with its own internal runner.\n",
        "\n",
        "**Q: How do I run pure bandit exploration?**\n",
        "A: Initialize with `engine=\"bandit\"` (the `policy` is ignored in that case) and tune `bandit_discount`, `bandit_c`, or pick a Beta-based strategy via the runner if you need.\n",
        "\n",
        "---\n",
        "\n",
        "## License\n",
        "\n",
        "Add your license terms here.\n"
      ],
      "metadata": {
        "id": "eYgu7KhSC9eN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlyqm9y6Lcqk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Package Installation"
      ],
      "metadata": {
        "id": "YrtRk0LyOwTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, csv\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import graphviz\n",
        "from IPython.display import display, Image\n",
        "\n",
        "from pydantic import BaseModel, ValidationError, field_validator\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "bBMu65ZtYn0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"git+https://github.com/mugalan/item-response-prediction.git\""
      ],
      "metadata": {
        "id": "4vfZQbWiYuT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from item_response import ItemResponsePrediction"
      ],
      "metadata": {
        "id": "GPDPK57tbEy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}